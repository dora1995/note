任何需求都可以做成你的亮点，只需要你把它的量级扩大，想得更严谨

实现拖拽，需要监听三个事件：dragover，dragleave，drop

可以做一个进度条，axios有专门的onUploadProgress，通过计算progress.loaded / progress.total

判断上传文件的格式，文件的文件流十六进制数据都有特定的代码段，百度文件头信息

```
async blobToString (blob) {
  return new Promise(resolve => {
    const reader = new FileReader()
    reader.onload = function () {
      const ret = reader.result.split('').map(v => v.toString(16).toUpperCase()).join('')
      resolve(ret)
    }
    reader.readAsBinaryString(blob)
    }
  )
}
```

用md5做文件的唯一标识，不能只用名字；用web-worker计算

- **js-spark-md5**，支持增量计算，npm下载后然后拷出来
- 文件计算很慢，还有为了不阻塞进程，使用worker多线程计算，通过postMessage和onMessage进行信息交互
- filerReader的使用，readAsArrayBuffer

断点续传，比如有一个2g的文件，在中间网络断开了，重新上传又要重新开始，这是不好的

- 切片，`1m = 1024*1024`
- 启动worker，调用md5

```
// worker代码

self.importScript('spark-md5.min.js')

self.onmessage = e => {
  const { chunk } = e.data
  const spark = new self.SparkMD5.ArrayBuffer()
  let progress = 0
  let count = 0
  const loadNext = index => {
    const reader = new FileReader()
    reader.readAsArrayBuffer(chunks[index].file)
    reader.onload = e => {
      count ++
      spark.md5(e.target.result)
      if (count == chunks.length) {
        self.postMessage({
          progress: 100,
          hash: spark.end()
        })
      } else {
        progress += 100 / chunks.length
        self.postMessage({
          progress
        })
        loadNext(count)
      }
    }
  }
}
```
